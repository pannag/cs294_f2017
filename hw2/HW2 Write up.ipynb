{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discrete CartPole-v0\n",
    "```\n",
    "python train_pg.py CartPole-v0 -n 100 -b 1000 -e 5 -dna --exp_name\n",
    "sb_no_rtg_dna \n",
    "python train_pg.py CartPole-v0 -n 100 -b 1000 -e 5 -rtg -dna --exp_name\n",
    "sb_rtg_dna\n",
    "python train_pg.py CartPole-v0 -n 100 -b 1000 -e 5 -rtg --exp_name\n",
    "sb_rtg_na\n",
    "python train_pg.py CartPole-v0 -n 100 -b 5000 -e 5 -dna --exp_name\n",
    "lb_no_rtg_dna\n",
    "python train_pg.py CartPole-v0 -n 100 -b 5000 -e 5 -rtg -dna --exp_name\n",
    "lb_rtg_dna\n",
    "python train_pg.py CartPole-v0 -n 100 -b 5000 -e 5 -rtg --exp_name\n",
    "lb_rtg_na\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small batch experiments\n",
    "<img src=\"Figure_Cartpole-v0.png\">\n",
    "\n",
    "### Large batch experiments\n",
    "<img src=\"Figure_lb_Cartpole-v0.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- Clearly, *reward_to_go=True* (\"rtg\") gives better results than the trajectory-centric one (\"no_rtg\"), \n",
    "- adding  advantage-centering i.e. *normalize_advantages=True* (\"rtg_na\") seems to only help marginally. \n",
    "- Using a large batch size helps the algorithm to converge faster, especially in the case of trajectory-centric PG estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InvertedPendulum-v1 continuous control\n",
    "<img src=\"Figure_RoboInvertedPendulum-v1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- *reward_to_go=True* (\"rtg\") gives better results than the trajectory-centric one (\"no_rtg\"), but only if   advantage-centering is not used i.e. *normalize_advantages=False* (\"rtg_dna\"). \n",
    "- The rewards go down after certain iterations. Seems like we are overfitting past 60 iterations.\n",
    "\n",
    "This was using default parameters. Might be worth experimenting with learning rate and batch sizes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Baseline\n",
    "<img src=\"Figure_RoboInvertedPendulum-v1-baseline1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observations\n",
    "- The baseline does not seem to help, at least in current parameter setting. \n",
    "- That said, the rewards go down after certain iterations. Seems like past 80 iterations, the baseline performs better, although in absolute terms, both are bad.\n",
    "\n",
    "This was using default parameters. Might be worth experimenting with learning rate and batch sizes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
